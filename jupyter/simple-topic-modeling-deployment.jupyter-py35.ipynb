{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Topic Modeling and Document Clustering with LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "TODO add description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# add scripts/ folder to path\n",
    "import os, sys\n",
    "\n",
    "SCRIPTS_PATH = os.environ['DSX_PROJECT_DIR'] + '/scripts'\n",
    "sys.path.insert(0, SCRIPTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import visualization # custom script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = \"/user-home/libraries/text-analytics/datasets/aclImdb\"\n",
    "TRAIN_PATH = DATASET_PATH + \"/train/\"\n",
    "TEST_PATH = DATASET_PATH + \"/test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 0. Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We only load the training data, without labels, and consider it as unlabeled data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of text_train: <class 'list'>\n",
      "length of text_train: 25000\n"
     ]
    }
   ],
   "source": [
    "reviews_train = load_files(TRAIN_PATH)\n",
    "text_train = reviews_train.data\n",
    "print(\"type of text_train: {}\".format(type(text_train)))\n",
    "print(\"length of text_train: {}\".format(len(text_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Even though the preprocessing is short and straightforward, we probably want to move this to a script at some point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "text_train = [doc.replace(b\"<br />\", b\" \").decode('utf-8') for doc in text_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "text_train = pd.DataFrame({\"review\": text_train})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We limit the number of features to speed up the topic modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      "<25000x10000 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 1948677 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(max_features=10000, max_df=.15)\n",
    "X_train = vect.fit_transform(text_train.review)\n",
    "print(\"X_train:\\n{}\".format(repr(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 10000\n",
      "First 20 features:\n",
      "['00', '000', '10', '100', '1000', '101', '11', '12', '13', '13th', '14', '15', '150', '16', '17', '18', '18th', '19', '1920', '1920s']\n",
      "Features 20010 to 20030:\n",
      "[]\n",
      "Every 2000th feature:\n",
      "['00', 'conroy', 'graphic', 'named', 'sharp']\n"
     ]
    }
   ],
   "source": [
    "feature_names = vect.get_feature_names()\n",
    "print(\"Number of features: {}\".format(len(feature_names)))\n",
    "print(\"First 20 features:\\n{}\".format(feature_names[:20]))\n",
    "print(\"Features 20010 to 20030:\\n{}\".format(feature_names[20010:20030]))\n",
    "print(\"Every 2000th feature:\\n{}\".format(feature_names[::2000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3. Build model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.2 Non-Negative Matrix Factorization (NMF), 10 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(FunctionTransformer(pd.DataFrame.get, kw_args={'key':'review'}, validate=False),\n",
    "                     CountVectorizer(),\n",
    "                     NMF(n_components=10, max_iter=25, random_state=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nmf.components_.shape: (10, 10000)\n",
      "CPU times: user 18.4 s, sys: 19 s, total: 37.4 s\n",
      "Wall time: 16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "document_topics_nmf = pipe.fit_transform(text_train)\n",
    "print(\"nmf.components_.shape: {}\".format(nmf.components_.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nmf = pipe.steps[2][1]\n",
    "vect = pipe.steps[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# for each topic (a row in the components_), sort the features (ascending).\n",
    "# Invert rows with [:, ::-1] to make sorting descending\n",
    "sorting_nmf = np.argsort(nmf.components_, axis=1)[:, ::-1]\n",
    "feature_names = np.array(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Explore the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0       topic 1       topic 2       topic 3       topic 4       \n",
      "--------      --------      --------      --------      --------      \n",
      "the           it            and           is            to            \n",
      "of            that          with          that          that          \n",
      "and           was           is            it            be            \n",
      "to            but           to            are           have          \n",
      "in            you           are           not           they          \n",
      "on            to            all           this          for           \n",
      "with          and           their         but           on            \n",
      "is            so            very          the           you           \n",
      "for           just          of            as            with          \n",
      "from          not           as            there         who           \n",
      "\n",
      "\n",
      "topic 5       topic 6       topic 7       topic 8       topic 9       \n",
      "--------      --------      --------      --------      --------      \n",
      "of            he            movie         film          her           \n",
      "in            his           this          this          she           \n",
      "as            in            was           in            in            \n",
      "that          was           you           as            with          \n",
      "one           as            in            films         as            \n",
      "with          him           movies        was           who           \n",
      "an            the           have          for           for           \n",
      "for           with          the           have          is            \n",
      "or            for           not           very          when          \n",
      "by            who           my            made          has           \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print out the 10 topics:\n",
    "visualization.print_topics(topics=range(10), feature_names=feature_names,\n",
    "                           sorting=sorting_nmf, topics_per_chunk=5, n_words=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Store model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Save model in ML repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dsx_ml.ml import save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'path': '/user-home/1055/DSX_Projects/text-deployment-demo/models/simple-topic-modeling/1', 'scoring_endpoint': 'https://dsxl-api/v3/project/score/Python35/scikit-learn-0.19/text-deployment-demo/simple-topic-modeling/1'}\n"
     ]
    }
   ],
   "source": [
    "deployment_info = save(name='simple-topic-modeling',\n",
    "                        model=pipe,\n",
    "                        algorithm_type='Classification', # Only classification and regression are supported\n",
    "                        description='This is the first simple topic modeling with NMF',\n",
    "                        source='simple-topic-modeling.ipynb')\n",
    "print(deployment_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Test model in Models UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UI doesn't support Unsupervised models with sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Test model with REST API call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can't directly use the API that's automatically generated for Unsupervised models with sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Create a custom scoring script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WS Local automatically support only classification and regression models for scikit-learn. Yet, deploying unsupervised models is also very easy and only requires a few steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. In the \"models\" section, select the model we just saved, and click on \"Generate custom scoring script\"**\n",
    "<img style=\"float: left;\" src=\"https://i.imgur.com/0LsTt5o.png\" alt=\"Step 1 - Create custom script\" width=900 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. This will generate a script with the same functions that are automatically generated when using the raw API/using the UI. Note that doing this is a good way of debugging a deployment that failed, in other cases. By default, the script is set to run as a web service. To debug it, we can set it as a job in the \"Run Configuration\" panel.**\n",
    "<img style=\"float: left;\" src=\"https://i.imgur.com/xi7vF9B.png\" alt=\"Step 2 - Modify custom script: switch to job\" width=900 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**3. To switch from classification to topic modeling, all we need to do is to identify the part where the predict() function is called, and switch it to transform() instead.**\n",
    "<img style=\"float: left;\" src=\"https://i.imgur.com/f1A4v5Q.png\" alt=\"Step 3 - Modify custom script: switch to transform()\" width=900 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**4. To try out the code modification, call the test_score() function within the script and print the result. Then save the script and run it. If the console output is hidden, drag it from the right of the screen.**\n",
    "<img style=\"float: left;\" src=\"https://i.imgur.com/v4yQHvK.png\" alt=\"Step 3 - Modify custom script: switch to transform()\" width=900 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Once the code is running, switch the \"Run configuration\" back to \"Web Service\", save it, and select the run button again. The UI will show the steps necessary to call this newly created API to be able to score the model**\n",
    "<img style=\"float: left;\" src=\"https://i.imgur.com/GmmS5kf.png\" alt=\"Step 3 - Modify custom script: switch to transform()\" width=900 />"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python3.5 with Watson Studio Spark 2.2.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
