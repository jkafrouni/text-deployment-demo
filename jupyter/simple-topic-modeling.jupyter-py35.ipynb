{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Topic Modeling and Document Clustering with LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "TODO add description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# add scripts/ folder to path\n",
    "import os, sys\n",
    "\n",
    "SCRIPTS_PATH = os.environ['DSX_PROJECT_DIR'] + '/scripts'\n",
    "sys.path.insert(0, SCRIPTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import visualization # custom script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = \"/user-home/libraries/text-analytics/datasets/aclImdb\"\n",
    "TRAIN_PATH = DATASET_PATH + \"/train/\"\n",
    "TEST_PATH = DATASET_PATH + \"/test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 0. Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We only load the training data, without labels, and consider it as unlabeled data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of text_train: <class 'list'>\n",
      "length of text_train: 25000\n"
     ]
    }
   ],
   "source": [
    "reviews_train = load_files(TRAIN_PATH)\n",
    "text_train = reviews_train.data\n",
    "print(\"type of text_train: {}\".format(type(text_train)))\n",
    "print(\"length of text_train: {}\".format(len(text_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Even though the preprocessing is short and straightforward, we probably want to move this to a script at some point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "text_train = [doc.replace(b\"<br />\", b\" \").decode('utf-8') for doc in text_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "text_train = pd.DataFrame({\"review\": text_train})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We limit the number of features to speed up the topic modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      "<25000x10000 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 1948677 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(max_features=10000, max_df=.15)\n",
    "X_train = vect.fit_transform(text_train.review)\n",
    "print(\"X_train:\\n{}\".format(repr(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 10000\n",
      "First 20 features:\n",
      "['00', '000', '10', '100', '1000', '101', '11', '12', '13', '13th', '14', '15', '150', '16', '17', '18', '18th', '19', '1920', '1920s']\n",
      "Features 20010 to 20030:\n",
      "[]\n",
      "Every 2000th feature:\n",
      "['00', 'conroy', 'graphic', 'named', 'sharp']\n"
     ]
    }
   ],
   "source": [
    "feature_names = vect.get_feature_names()\n",
    "print(\"Number of features: {}\".format(len(feature_names)))\n",
    "print(\"First 20 features:\\n{}\".format(feature_names[:20]))\n",
    "print(\"Features 20010 to 20030:\\n{}\".format(feature_names[20010:20030]))\n",
    "print(\"Every 2000th feature:\\n{}\".format(feature_names[::2000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3. Build model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.1 Latent Dirichlet Allocation (LDA), 10 topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Training LDA on the full data is very slow, and training it on a subset of the data gives \"bad\" topics: instead, we only perform NMF -> see section 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# lda = LatentDirichletAllocation(n_components=10, learning_method=\"batch\",\n",
    "#                                 max_iter=25, random_state=0)\n",
    "# document_topics = lda.fit_transform(X_train)\n",
    "# print(\"lda.components_.shape: {}\".format(lda.components_.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# # for each topic (a row in the components_), sort the features (ascending).\n",
    "# # Invert rows with [:, ::-1] to make sorting descending\n",
    "# sorting = np.argsort(lda.components_, axis=1)[:, ::-1]\n",
    "# # get the feature names from the vectorizer:\n",
    "# feature_names = np.array(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Explore the topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# # Print out the 10 topics:\n",
    "# visualization.print_topics(topics=range(10), feature_names=feature_names,\n",
    "#                            sorting=sorting, topics_per_chunk=5, n_words=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.2 Non-Negative Matrix Factorization (NMF), 10 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nmf.components_.shape: (10, 10000)\n",
      "CPU times: user 4.54 s, sys: 11.4 s, total: 16 s\n",
      "Wall time: 3.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nmf = NMF(n_components=10, max_iter=25, random_state=0)\n",
    "document_topics_nmf = nmf.fit_transform(X_train)\n",
    "print(\"nmf.components_.shape: {}\".format(nmf.components_.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# for each topic (a row in the components_), sort the features (ascending).\n",
    "# Invert rows with [:, ::-1] to make sorting descending\n",
    "sorting_nmf = np.argsort(nmf.components_, axis=1)[:, ::-1]\n",
    "feature_names = np.array(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Explore the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0       topic 1       topic 2       topic 3       topic 4       \n",
      "--------      --------      --------      --------      --------      \n",
      "director      show          re            series        horror        \n",
      "work          shows         thing         original      house         \n",
      "role          episode       nothing       episode       gore          \n",
      "performance   tv            didn          new           blood         \n",
      "quite         season        going         episodes      zombie        \n",
      "cast          episodes      guy           tv            effects       \n",
      "though        television    actually      season        budget        \n",
      "actors        funny         doesn         years         dead          \n",
      "however       always        minutes       batman        scary         \n",
      "both          real          want          star          killer        \n",
      "\n",
      "\n",
      "topic 5       topic 6       topic 7       topic 8       topic 9       \n",
      "--------      --------      --------      --------      --------      \n",
      "us            match         family        book          10            \n",
      "world         rock          young         jane          funny         \n",
      "war           ring          old           version       comedy        \n",
      "our           angle         father        read          years         \n",
      "real          taker         woman         novel         music         \n",
      "american      got           mother        rochester     old           \n",
      "own           big           wife          eyre          saw           \n",
      "human         championship  girl          original      give          \n",
      "new           vs            years         adaptation    fun           \n",
      "point         down          son           dalton        year          \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print out the 10 topics:\n",
    "visualization.print_topics(topics=range(10), feature_names=feature_names,\n",
    "                           sorting=sorting_nmf, topics_per_chunk=5, n_words=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**TODO find an interesting topic and explore it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # sort by weight of \"music\" topic 45\n",
    "# music = np.argsort(document_topics100[:, 45])[::-1]\n",
    "# # print the five documents where the topic is most important\n",
    "# for i in music[:10]:\n",
    "#     # show first two sentences\n",
    "#     print(b\".\".join(text_train[i].split(b\".\")[:2]) + b\".\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, 2, figsize=(10, 10))\n",
    "# topic_names = [\"{:>2} \".format(i) + \" \".join(words)\n",
    "#                for i, words in enumerate(feature_names[sorting[:, :2]])]\n",
    "# # two column bar chart:\n",
    "# for col in [0, 1]:\n",
    "#     start = col * 50\n",
    "#     end = (col + 1) * 50\n",
    "#     ax[col].barh(np.arange(50), np.sum(document_topics100, axis=0)[start:end])\n",
    "#     ax[col].set_yticks(np.arange(50))\n",
    "#     ax[col].set_yticklabels(topic_names[start:end], ha=\"left\", va=\"top\")\n",
    "#     ax[col].invert_yaxis()\n",
    "#     ax[col].set_xlim(0, 2000)\n",
    "#     yax = ax[col].get_yaxis()\n",
    "#     yax.set_tick_params(pad=130)\n",
    "# plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python3.5 with Watson Studio Spark 2.2.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
